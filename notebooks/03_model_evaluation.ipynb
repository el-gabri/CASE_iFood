{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelagem e Avaliação para Detecção de Fraude\n",
    "\n",
    "Este notebook demonstra o processo de modelagem, avaliação e interpretação dos resultados para o projeto de detecção de fraude em transações de cartão de crédito. Vamos treinar diferentes modelos de machine learning e avaliar seu desempenho.\n",
    "\n",
    "## Conteúdo\n",
    "1. [Configuração do Ambiente](#1.-Configuração-do-Ambiente)\n",
    "2. [Carregamento dos Dados](#2.-Carregamento-dos-Dados)\n",
    "3. [Treinamento dos Modelos](#3.-Treinamento-dos-Modelos)\n",
    "   - [Regressão Logística](#3.1-Regressão-Logística)\n",
    "   - [Random Forest](#3.2-Random-Forest)\n",
    "   - [Gradient Boosted Trees](#3.3-Gradient-Boosted-Trees)\n",
    "   - [XGBoost](#3.4-XGBoost)\n",
    "4. [Avaliação dos Modelos](#4.-Avaliação-dos-Modelos)\n",
    "   - [Métricas de Desempenho](#4.1-Métricas-de-Desempenho)\n",
    "   - [Curvas ROC](#4.2-Curvas-ROC)\n",
    "   - [Matrizes de Confusão](#4.3-Matrizes-de-Confusão)\n",
    "5. [Importância das Features](#5.-Importância-das-Features)\n",
    "6. [Otimização de Hiperparâmetros](#6.-Otimização-de-Hiperparâmetros)\n",
    "7. [Modelo Final](#7.-Modelo-Final)\n",
    "8. [Salvando o Modelo](#8.-Salvando-o-Modelo)\n",
    "9. [Conclusões](#9.-Conclusões)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuração do Ambiente\n",
    "\n",
    "Vamos importar as bibliotecas necessárias e configurar o ambiente para nossa análise."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T01:01:36.774802Z",
     "start_time": "2025-05-22T01:01:36.401834Z"
    }
   },
   "source": [
    "# Importar bibliotecas necessárias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import sys\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "\n",
    "# Bibliotecas de machine learning\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, confusion_matrix, classification_report,\n",
    "    roc_curve, precision_recall_curve, average_precision_score\n",
    ")\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "import xgboost as xgb\n",
    "\n",
    "# Configurações de visualização\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_theme(style='whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "# Configurar exibição de dados no pandas\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.float_format', '{:.4f}'.format)\n",
    "\n",
    "# Ignorar warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Carregamento dos Dados\n",
    "\n",
    "Vamos carregar os dados processados que foram preparados no notebook anterior."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T01:02:58.544486Z",
     "start_time": "2025-05-22T01:01:37.938586Z"
    }
   },
   "source": [
    "# Definir caminhos para os arquivos\n",
    "# Ajuste os caminhos conforme necessário para seu ambiente\n",
    "base_dir = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "data_dir = os.path.join(base_dir, 'data')\n",
    "processed_dir = os.path.join(data_dir, 'processed')\n",
    "models_dir = os.path.join(base_dir, 'models')\n",
    "reports_dir = os.path.join(base_dir, 'reports')\n",
    "\n",
    "# Garantir que os diretórios existem\n",
    "for directory in [processed_dir, models_dir, reports_dir]:\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "# Caminhos para os arquivos de dados processados\n",
    "X_train_path = os.path.join(processed_dir, 'X_train.csv')\n",
    "y_train_path = os.path.join(processed_dir, 'y_train.csv')\n",
    "X_test_path = os.path.join(processed_dir, 'X_test.csv')\n",
    "y_test_path = os.path.join(processed_dir, 'y_test.csv')\n",
    "feature_cols_path = os.path.join(processed_dir, 'feature_cols.txt')\n",
    "\n",
    "# Verificar se os arquivos existem\n",
    "if not all(os.path.exists(p) for p in [X_train_path, y_train_path, X_test_path, y_test_path]):\n",
    "    print(f\"Erro: Arquivos de dados processados não encontrados em {processed_dir}\")\n",
    "    print(\"Execute o notebook de engenharia de features primeiro.\")\n",
    "else:\n",
    "    # Carregar os dados\n",
    "    print(\"Carregando dados processados...\")\n",
    "    X_train = pd.read_csv(X_train_path)\n",
    "    y_train = pd.read_csv(y_train_path).values.ravel()\n",
    "    X_test = pd.read_csv(X_test_path)\n",
    "    y_test = pd.read_csv(y_test_path).values.ravel()\n",
    "    \n",
    "    # Carregar lista de features se disponível\n",
    "    if os.path.exists(feature_cols_path):\n",
    "        with open(feature_cols_path, 'r') as f:\n",
    "            feature_cols = [line.strip() for line in f.readlines()]\n",
    "    else:\n",
    "        feature_cols = X_train.columns.tolist()\n",
    "    \n",
    "    print(f\"Conjunto de treino: {X_train.shape[0]} amostras, {X_train.shape[1]} features\")\n",
    "    print(f\"Conjunto de teste: {X_test.shape[0]} amostras, {X_test.shape[1]} features\")\n",
    "    print(f\"Distribuição da classe alvo (treino): {np.bincount(y_train)}\")\n",
    "    print(f\"Distribuição da classe alvo (teste): {np.bincount(y_test)}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carregando dados processados...\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 5.81 GiB for an array with shape (1404, 555719) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mMemoryError\u001B[39m                               Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[3]\u001B[39m\u001B[32m, line 29\u001B[39m\n\u001B[32m     27\u001B[39m X_train = pd.read_csv(X_train_path)\n\u001B[32m     28\u001B[39m y_train = pd.read_csv(y_train_path).values.ravel()\n\u001B[32m---> \u001B[39m\u001B[32m29\u001B[39m X_test = \u001B[43mpd\u001B[49m\u001B[43m.\u001B[49m\u001B[43mread_csv\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_test_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     30\u001B[39m y_test = pd.read_csv(y_test_path).values.ravel()\n\u001B[32m     32\u001B[39m \u001B[38;5;66;03m# Carregar lista de features se disponível\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\anaconda3\\envs\\CASE_iFood\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001B[39m, in \u001B[36mread_csv\u001B[39m\u001B[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001B[39m\n\u001B[32m   1013\u001B[39m kwds_defaults = _refine_defaults_read(\n\u001B[32m   1014\u001B[39m     dialect,\n\u001B[32m   1015\u001B[39m     delimiter,\n\u001B[32m   (...)\u001B[39m\u001B[32m   1022\u001B[39m     dtype_backend=dtype_backend,\n\u001B[32m   1023\u001B[39m )\n\u001B[32m   1024\u001B[39m kwds.update(kwds_defaults)\n\u001B[32m-> \u001B[39m\u001B[32m1026\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_read\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\anaconda3\\envs\\CASE_iFood\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:626\u001B[39m, in \u001B[36m_read\u001B[39m\u001B[34m(filepath_or_buffer, kwds)\u001B[39m\n\u001B[32m    623\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m parser\n\u001B[32m    625\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m parser:\n\u001B[32m--> \u001B[39m\u001B[32m626\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mparser\u001B[49m\u001B[43m.\u001B[49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnrows\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\anaconda3\\envs\\CASE_iFood\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1968\u001B[39m, in \u001B[36mTextFileReader.read\u001B[39m\u001B[34m(self, nrows)\u001B[39m\n\u001B[32m   1965\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m   1966\u001B[39m         new_col_dict = col_dict\n\u001B[32m-> \u001B[39m\u001B[32m1968\u001B[39m     df = \u001B[43mDataFrame\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1969\u001B[39m \u001B[43m        \u001B[49m\u001B[43mnew_col_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1970\u001B[39m \u001B[43m        \u001B[49m\u001B[43mcolumns\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcolumns\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1971\u001B[39m \u001B[43m        \u001B[49m\u001B[43mindex\u001B[49m\u001B[43m=\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1972\u001B[39m \u001B[43m        \u001B[49m\u001B[43mcopy\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43musing_copy_on_write\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1973\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1975\u001B[39m     \u001B[38;5;28mself\u001B[39m._currow += new_rows\n\u001B[32m   1976\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m df\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\anaconda3\\envs\\CASE_iFood\\Lib\\site-packages\\pandas\\core\\frame.py:778\u001B[39m, in \u001B[36mDataFrame.__init__\u001B[39m\u001B[34m(self, data, index, columns, dtype, copy)\u001B[39m\n\u001B[32m    772\u001B[39m     mgr = \u001B[38;5;28mself\u001B[39m._init_mgr(\n\u001B[32m    773\u001B[39m         data, axes={\u001B[33m\"\u001B[39m\u001B[33mindex\u001B[39m\u001B[33m\"\u001B[39m: index, \u001B[33m\"\u001B[39m\u001B[33mcolumns\u001B[39m\u001B[33m\"\u001B[39m: columns}, dtype=dtype, copy=copy\n\u001B[32m    774\u001B[39m     )\n\u001B[32m    776\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data, \u001B[38;5;28mdict\u001B[39m):\n\u001B[32m    777\u001B[39m     \u001B[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m778\u001B[39m     mgr = \u001B[43mdict_to_mgr\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindex\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcolumns\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcopy\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcopy\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtyp\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmanager\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    779\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data, ma.MaskedArray):\n\u001B[32m    780\u001B[39m     \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mnumpy\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mma\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m mrecords\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\anaconda3\\envs\\CASE_iFood\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:503\u001B[39m, in \u001B[36mdict_to_mgr\u001B[39m\u001B[34m(data, index, columns, dtype, typ, copy)\u001B[39m\n\u001B[32m    499\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    500\u001B[39m         \u001B[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001B[39;00m\n\u001B[32m    501\u001B[39m         arrays = [x.copy() \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(x, \u001B[33m\"\u001B[39m\u001B[33mdtype\u001B[39m\u001B[33m\"\u001B[39m) \u001B[38;5;28;01melse\u001B[39;00m x \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m arrays]\n\u001B[32m--> \u001B[39m\u001B[32m503\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43marrays_to_mgr\u001B[49m\u001B[43m(\u001B[49m\u001B[43marrays\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcolumns\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindex\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtyp\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtyp\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconsolidate\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcopy\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\anaconda3\\envs\\CASE_iFood\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:152\u001B[39m, in \u001B[36marrays_to_mgr\u001B[39m\u001B[34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001B[39m\n\u001B[32m    149\u001B[39m axes = [columns, index]\n\u001B[32m    151\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m typ == \u001B[33m\"\u001B[39m\u001B[33mblock\u001B[39m\u001B[33m\"\u001B[39m:\n\u001B[32m--> \u001B[39m\u001B[32m152\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mcreate_block_manager_from_column_arrays\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    153\u001B[39m \u001B[43m        \u001B[49m\u001B[43marrays\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconsolidate\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconsolidate\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrefs\u001B[49m\u001B[43m=\u001B[49m\u001B[43mrefs\u001B[49m\n\u001B[32m    154\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    155\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m typ == \u001B[33m\"\u001B[39m\u001B[33marray\u001B[39m\u001B[33m\"\u001B[39m:\n\u001B[32m    156\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m ArrayManager(arrays, [index, columns])\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\anaconda3\\envs\\CASE_iFood\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:2144\u001B[39m, in \u001B[36mcreate_block_manager_from_column_arrays\u001B[39m\u001B[34m(arrays, axes, consolidate, refs)\u001B[39m\n\u001B[32m   2142\u001B[39m     raise_construction_error(\u001B[38;5;28mlen\u001B[39m(arrays), arrays[\u001B[32m0\u001B[39m].shape, axes, e)\n\u001B[32m   2143\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m consolidate:\n\u001B[32m-> \u001B[39m\u001B[32m2144\u001B[39m     \u001B[43mmgr\u001B[49m\u001B[43m.\u001B[49m\u001B[43m_consolidate_inplace\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   2145\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m mgr\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\anaconda3\\envs\\CASE_iFood\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:1788\u001B[39m, in \u001B[36mBlockManager._consolidate_inplace\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m   1782\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m_consolidate_inplace\u001B[39m(\u001B[38;5;28mself\u001B[39m) -> \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m   1783\u001B[39m     \u001B[38;5;66;03m# In general, _consolidate_inplace should only be called via\u001B[39;00m\n\u001B[32m   1784\u001B[39m     \u001B[38;5;66;03m#  DataFrame._consolidate_inplace, otherwise we will fail to invalidate\u001B[39;00m\n\u001B[32m   1785\u001B[39m     \u001B[38;5;66;03m#  the DataFrame's _item_cache. The exception is for newly-created\u001B[39;00m\n\u001B[32m   1786\u001B[39m     \u001B[38;5;66;03m#  BlockManager objects not yet attached to a DataFrame.\u001B[39;00m\n\u001B[32m   1787\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m.is_consolidated():\n\u001B[32m-> \u001B[39m\u001B[32m1788\u001B[39m         \u001B[38;5;28mself\u001B[39m.blocks = \u001B[43m_consolidate\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mblocks\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1789\u001B[39m         \u001B[38;5;28mself\u001B[39m._is_consolidated = \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[32m   1790\u001B[39m         \u001B[38;5;28mself\u001B[39m._known_consolidated = \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\anaconda3\\envs\\CASE_iFood\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:2269\u001B[39m, in \u001B[36m_consolidate\u001B[39m\u001B[34m(blocks)\u001B[39m\n\u001B[32m   2267\u001B[39m new_blocks: \u001B[38;5;28mlist\u001B[39m[Block] = []\n\u001B[32m   2268\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m (_can_consolidate, dtype), group_blocks \u001B[38;5;129;01min\u001B[39;00m grouper:\n\u001B[32m-> \u001B[39m\u001B[32m2269\u001B[39m     merged_blocks, _ = \u001B[43m_merge_blocks\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   2270\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mgroup_blocks\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcan_consolidate\u001B[49m\u001B[43m=\u001B[49m\u001B[43m_can_consolidate\u001B[49m\n\u001B[32m   2271\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   2272\u001B[39m     new_blocks = extend_blocks(merged_blocks, new_blocks)\n\u001B[32m   2273\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mtuple\u001B[39m(new_blocks)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\anaconda3\\envs\\CASE_iFood\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:2301\u001B[39m, in \u001B[36m_merge_blocks\u001B[39m\u001B[34m(blocks, dtype, can_consolidate)\u001B[39m\n\u001B[32m   2298\u001B[39m     new_values = bvals2[\u001B[32m0\u001B[39m]._concat_same_type(bvals2, axis=\u001B[32m0\u001B[39m)\n\u001B[32m   2300\u001B[39m argsort = np.argsort(new_mgr_locs)\n\u001B[32m-> \u001B[39m\u001B[32m2301\u001B[39m new_values = \u001B[43mnew_values\u001B[49m\u001B[43m[\u001B[49m\u001B[43margsort\u001B[49m\u001B[43m]\u001B[49m\n\u001B[32m   2302\u001B[39m new_mgr_locs = new_mgr_locs[argsort]\n\u001B[32m   2304\u001B[39m bp = BlockPlacement(new_mgr_locs)\n",
      "\u001B[31mMemoryError\u001B[39m: Unable to allocate 5.81 GiB for an array with shape (1404, 555719) and data type float64"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T01:02:58.559998700Z",
     "start_time": "2025-05-22T00:58:53.331565Z"
    }
   },
   "source": [
    "# Verificar as primeiras linhas dos dados\n",
    "print(\"Primeiras linhas do conjunto de treino:\")\n",
    "X_train.head()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primeiras linhas do conjunto de treino:\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[1]\u001B[39m\u001B[32m, line 3\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;66;03m# Verificar as primeiras linhas dos dados\u001B[39;00m\n\u001B[32m      2\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33mPrimeiras linhas do conjunto de treino:\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m----> \u001B[39m\u001B[32m3\u001B[39m \u001B[43mX_train\u001B[49m.head()\n",
      "\u001B[31mNameError\u001B[39m: name 'X_train' is not defined"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Treinamento dos Modelos\n",
    "\n",
    "Vamos treinar diferentes modelos de machine learning para detecção de fraude."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Regressão Logística\n",
    "\n",
    "Começaremos com um modelo de Regressão Logística como baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para treinar modelo de Regressão Logística\n",
    "def train_logistic_regression(X_train, y_train):\n",
    "    print(\"Treinando modelo de Regressão Logística...\")\n",
    "    \n",
    "    # Inicializar e treinar o modelo\n",
    "    model = LogisticRegression(\n",
    "        C=1.0,                # Inverso da força de regularização\n",
    "        penalty='l2',         # Tipo de regularização (L2)\n",
    "        solver='liblinear',   # Algoritmo de otimização\n",
    "        max_iter=1000,        # Número máximo de iterações\n",
    "        class_weight='balanced', # Pesos das classes para lidar com desbalanceamento\n",
    "        random_state=42       # Semente aleatória para reprodutibilidade\n",
    "    )\n",
    "    \n",
    "    # Treinar o modelo\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    print(\"Modelo de Regressão Logística treinado com sucesso!\")\n",
    "    return model\n",
    "\n",
    "# Treinar modelo de Regressão Logística\n",
    "lr_model = train_logistic_regression(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Random Forest\n",
    "\n",
    "Agora, vamos treinar um modelo de Random Forest, que geralmente tem bom desempenho em problemas de classificação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para treinar modelo Random Forest\n",
    "def train_random_forest(X_train, y_train):\n",
    "    print(\"Treinando modelo Random Forest...\")\n",
    "    \n",
    "    # Inicializar e treinar o modelo\n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=100,     # Número de árvores\n",
    "        max_depth=None,       # Profundidade máxima das árvores\n",
    "        min_samples_split=2,  # Número mínimo de amostras para dividir um nó\n",
    "        min_samples_leaf=1,   # Número mínimo de amostras em um nó folha\n",
    "        max_features='sqrt',  # Número de features a considerar em cada divisão\n",
    "        bootstrap=True,       # Usar bootstrap para construir árvores\n",
    "        class_weight='balanced', # Pesos das classes para lidar com desbalanceamento\n",
    "        random_state=42,      # Semente aleatória para reprodutibilidade\n",
    "        n_jobs=-1             # Usar todos os processadores disponíveis\n",
    "    )\n",
    "    \n",
    "    # Treinar o modelo\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    print(\"Modelo Random Forest treinado com sucesso!\")\n",
    "    return model\n",
    "\n",
    "# Treinar modelo Random Forest\n",
    "rf_model = train_random_forest(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Gradient Boosted Trees\n",
    "\n",
    "Vamos treinar um modelo de Gradient Boosted Trees, que geralmente tem desempenho superior em muitos problemas de classificação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para treinar modelo Gradient Boosted Trees\n",
    "def train_gradient_boosting(X_train, y_train):\n",
    "    print(\"Treinando modelo Gradient Boosted Trees...\")\n",
    "    \n",
    "    # Inicializar e treinar o modelo\n",
    "    model = GradientBoostingClassifier(\n",
    "        n_estimators=100,     # Número de árvores\n",
    "        learning_rate=0.1,    # Taxa de aprendizado\n",
    "        max_depth=3,          # Profundidade máxima das árvores\n",
    "        min_samples_split=2,  # Número mínimo de amostras para dividir um nó\n",
    "        min_samples_leaf=1,   # Número mínimo de amostras em um nó folha\n",
    "        subsample=1.0,        # Fração de amostras para treinar cada árvore\n",
    "        max_features=None,    # Número de features a considerar em cada divisão\n",
    "        random_state=42       # Semente aleatória para reprodutibilidade\n",
    "    )\n",
    "    \n",
    "    # Treinar o modelo\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    print(\"Modelo Gradient Boosted Trees treinado com sucesso!\")\n",
    "    return model\n",
    "\n",
    "# Treinar modelo Gradient Boosted Trees\n",
    "gb_model = train_gradient_boosting(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 XGBoost\n",
    "\n",
    "Por fim, vamos treinar um modelo XGBoost, que é uma implementação otimizada de Gradient Boosting e geralmente apresenta excelente desempenho."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para treinar modelo XGBoost\n",
    "def train_xgboost(X_train, y_train):\n",
    "    print(\"Treinando modelo XGBoost...\")\n",
    "    \n",
    "    # Calcular scale_pos_weight para lidar com desbalanceamento\n",
    "    scale_pos_weight = np.sum(y_train == 0) / np.sum(y_train == 1)\n",
    "    \n",
    "    # Inicializar e treinar o modelo\n",
    "    model = xgb.XGBClassifier(\n",
    "        n_estimators=100,     # Número de árvores\n",
    "        learning_rate=0.1,    # Taxa de aprendizado\n",
    "        max_depth=3,          # Profundidade máxima das árvores\n",
    "        min_child_weight=1,   # Soma mínima de peso de instância necessária em um nó folha\n",
    "        gamma=0,              # Redução mínima da perda para fazer uma divisão\n",
    "        subsample=1.0,        # Fração de amostras para treinar cada árvore\n",
    "        colsample_bytree=1.0, # Fração de colunas para treinar cada árvore\n",
    "        objective='binary:logistic', # Função objetivo para classificação binária\n",
    "        scale_pos_weight=scale_pos_weight, # Peso da classe positiva para desbalanceamento\n",
    "        random_state=42,      # Semente aleatória para reprodutibilidade\n",
    "        use_label_encoder=False, # Não usar label encoder (deprecated)\n",
    "        eval_metric='logloss' # Métrica de avaliação\n",
    "    )\n",
    "    \n",
    "    # Treinar o modelo\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    print(\"Modelo XGBoost treinado com sucesso!\")\n",
    "    return model\n",
    "\n",
    "# Treinar modelo XGBoost\n",
    "xgb_model = train_xgboost(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Avaliação dos Modelos\n",
    "\n",
    "Vamos avaliar o desempenho dos modelos treinados usando diferentes métricas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Métricas de Desempenho\n",
    "\n",
    "Vamos calcular métricas como acurácia, precisão, recall, F1-score e AUC-ROC para cada modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para avaliar modelo\n",
    "def evaluate_model(model, X_test, y_test, model_name):\n",
    "    print(f\"\\nAvaliando modelo: {model_name}\")\n",
    "    \n",
    "    # Fazer previsões\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_prob = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Calcular métricas\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    auc = roc_auc_score(y_test, y_prob)\n",
    "    \n",
    "    # Calcular matriz de confusão\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    \n",
    "    # Imprimir métricas\n",
    "    print(f\"Acurácia: {accuracy:.4f}\")\n",
    "    print(f\"Precisão: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1-Score: {f1:.4f}\")\n",
    "    print(f\"AUC-ROC: {auc:.4f}\")\n",
    "    print(f\"Matriz de Confusão:\")\n",
    "    print(f\"TN: {tn}, FP: {fp}\")\n",
    "    print(f\"FN: {fn}, TP: {tp}\")\n",
    "    \n",
    "    # Retornar resultados como dicionário\n",
    "    results = {\n",
    "        'model': model_name,\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'auc': auc,\n",
    "        'tn': tn,\n",
    "        'fp': fp,\n",
    "        'fn': fn,\n",
    "        'tp': tp\n",
    "    }\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Avaliar todos os modelos\n",
    "models = {\n",
    "    'Logistic Regression': lr_model,\n",
    "    'Random Forest': rf_model,\n",
    "    'Gradient Boosted Trees': gb_model,\n",
    "    'XGBoost': xgb_model\n",
    "}\n",
    "\n",
    "# Lista para armazenar resultados\n",
    "results_list = []\n",
    "\n",
    "# Avaliar cada modelo\n",
    "for model_name, model in models.items():\n",
    "    results = evaluate_model(model, X_test, y_test, model_name)\n",
    "    results_list.append(results)\n",
    "\n",
    "# Criar DataFrame com resultados\n",
    "results_df = pd.DataFrame(results_list)\n",
    "\n",
    "# Exibir resultados\n",
    "print(\"\\nComparação dos modelos:\")\n",
    "results_df[['model', 'accuracy', 'precision', 'recall', 'f1', 'auc']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar resultados em gráfico de barras\n",
    "metrics = ['precision', 'recall', 'f1', 'auc']\n",
    "fig, ax = plt.subplots(figsize=(14, 8))\n",
    "\n",
    "# Configurar largura das barras\n",
    "bar_width = 0.2\n",
    "index = np.arange(len(results_df))\n",
    "\n",
    "# Plotar barras para cada métrica\n",
    "for i, metric in enumerate(metrics):\n",
    "    ax.bar(index + i*bar_width, results_df[metric], bar_width, label=metric.upper())\n",
    "\n",
    "# Configurar eixos e legendas\n",
    "ax.set_xlabel('Modelo', fontsize=12)\n",
    "ax.set_ylabel('Valor', fontsize=12)\n",
    "ax.set_title('Comparação de Métricas por Modelo', fontsize=14)\n",
    "ax.set_xticks(index + bar_width * (len(metrics) - 1) / 2)\n",
    "ax.set_xticklabels(results_df['model'])\n",
    "ax.legend()\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Adicionar valores nas barras\n",
    "for i, metric in enumerate(metrics):\n",
    "    for j, value in enumerate(results_df[metric]):\n",
    "        ax.text(j + i*bar_width, value + 0.01, f'{value:.3f}', \n",
    "                ha='center', va='bottom', rotation=90, fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Curvas ROC\n",
    "\n",
    "Vamos plotar as curvas ROC para cada modelo, que mostram a relação entre a taxa de verdadeiros positivos e a taxa de falsos positivos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para plotar curva ROC\n",
    "def plot_roc_curves(models, X_test, y_test):\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    # Plotar linha de referência (classificador aleatório)\n",
    "    plt.plot([0, 1], [0, 1], 'k--', label='Classificador Aleatório')\n",
    "    \n",
    "    # Plotar curva ROC para cada modelo\n",
    "    for model_name, model in models.items():\n",
    "        y_prob = model.predict_proba(X_test)[:, 1]\n",
    "        fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
    "        auc = roc_auc_score(y_test, y_prob)\n",
    "        plt.plot(fpr, tpr, label=f'{model_name} (AUC = {auc:.4f})')\n",
    "    \n",
    "    # Configurar gráfico\n",
    "    plt.xlabel('Taxa de Falsos Positivos', fontsize=12)\n",
    "    plt.ylabel('Taxa de Verdadeiros Positivos', fontsize=12)\n",
    "    plt.title('Curvas ROC para Diferentes Modelos', fontsize=14)\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.grid(alpha=0.3)\n",
    "    \n",
    "    # Salvar gráfico\n",
    "    plt.savefig(os.path.join(reports_dir, 'roc_curves.png'), dpi=300, bbox_inches='tight')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# Plotar curvas ROC\n",
    "plot_roc_curves(models, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para plotar curvas Precision-Recall\n",
    "def plot_precision_recall_curves(models, X_test, y_test):\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    # Plotar linha de referência (proporção da classe positiva)\n",
    "    no_skill = len(y_test[y_test == 1]) / len(y_test)\n",
    "    plt.plot([0, 1], [no_skill, no_skill], 'k--', label='Classificador Aleatório')\n",
    "    \n",
    "    # Plotar curva Precision-Recall para cada modelo\n",
    "    for model_name, model in models.items():\n",
    "        y_prob = model.predict_proba(X_test)[:, 1]\n",
    "        precision, recall, _ = precision_recall_curve(y_test, y_prob)\n",
    "        ap = average_precision_score(y_test, y_prob)\n",
    "        plt.plot(recall, precision, label=f'{model_name} (AP = {ap:.4f})')\n",
    "    \n",
    "    # Configurar gráfico\n",
    "    plt.xlabel('Recall', fontsize=12)\n",
    "    plt.ylabel('Precisão', fontsize=12)\n",
    "    plt.title('Curvas Precision-Recall para Diferentes Modelos', fontsize=14)\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.grid(alpha=0.3)\n",
    "    \n",
    "    # Salvar gráfico\n",
    "    plt.savefig(os.path.join(reports_dir, 'precision_recall_curves.png'), dpi=300, bbox_inches='tight')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# Plotar curvas Precision-Recall\n",
    "plot_precision_recall_curves(models, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Matrizes de Confusão\n",
    "\n",
    "Vamos visualizar as matrizes de confusão para cada modelo, que mostram os verdadeiros positivos, falsos positivos, verdadeiros negativos e falsos negativos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para plotar matriz de confusão\n",
    "def plot_confusion_matrix(model, X_test, y_test, model_name):\n",
    "    # Fazer previsões\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calcular matriz de confusão\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    # Plotar matriz de confusão\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
    "                xticklabels=['Não Fraude', 'Fraude'],\n",
    "                yticklabels=['Não Fraude', 'Fraude'])\n",
    "    plt.xlabel('Previsto', fontsize=12)\n",
    "    plt.ylabel('Real', fontsize=12)\n",
    "    plt.title(f'Matriz de Confusão - {model_name}', fontsize=14)\n",
    "    \n",
    "    # Salvar gráfico\n",
    "    plt.savefig(os.path.join(reports_dir, f'confusion_matrix_{model_name.replace(\" \", \"_\").lower()}.png'), \n",
    "                dpi=300, bbox_inches='tight')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# Identificar o melhor modelo com base no F1-Score\n",
    "best_model_idx = results_df['f1'].idxmax()\n",
    "best_model_name = results_df.loc[best_model_idx, 'model']\n",
    "best_model = models[best_model_name]\n",
    "\n",
    "# Plotar matriz de confusão para o melhor modelo\n",
    "print(f\"Matriz de confusão para o melhor modelo ({best_model_name}):\")\n",
    "plot_confusion_matrix(best_model, X_test, y_test, best_model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Importância das Features\n",
    "\n",
    "Vamos analisar a importância das features para entender quais são os principais fatores que influenciam a detecção de fraude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para plotar importância das features\n",
    "def plot_feature_importance(model, feature_cols, model_name, top_n=20):\n",
    "    # Verificar se o modelo suporta importância de features\n",
    "    if not hasattr(model, 'feature_importances_'):\n",
    "        print(f\"O modelo {model_name} não suporta importância de features.\")\n",
    "        return\n",
    "    \n",
    "    # Obter importância das features\n",
    "    importances = model.feature_importances_\n",
    "    \n",
    "    # Criar DataFrame com importância das features\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'Feature': feature_cols,\n",
    "        'Importance': importances\n",
    "    })\n",
    "    \n",
    "    # Ordenar por importância\n",
    "    feature_importance = feature_importance.sort_values('Importance', ascending=False)\n",
    "    \n",
    "    # Limitar ao top_n features\n",
    "    if len(feature_importance) > top_n:\n",
    "        feature_importance = feature_importance.head(top_n)\n",
    "    \n",
    "    # Plotar importância das features\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.barplot(x='Importance', y='Feature', data=feature_importance)\n",
    "    plt.title(f'Top {top_n} Features Mais Importantes - {model_name}', fontsize=14)\n",
    "    plt.xlabel('Importância', fontsize=12)\n",
    "    plt.ylabel('Feature', fontsize=12)\n",
    "    plt.grid(axis='x', alpha=0.3)\n",
    "    \n",
    "    # Salvar gráfico\n",
    "    plt.savefig(os.path.join(reports_dir, f'feature_importance_{model_name.replace(\" \", \"_\").lower()}.png'), \n",
    "                dpi=300, bbox_inches='tight')\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    return feature_importance\n",
    "\n",
    "# Plotar importância das features para o melhor modelo\n",
    "print(f\"Importância das features para o melhor modelo ({best_model_name}):\")\n",
    "feature_importance = plot_feature_importance(best_model, feature_cols, best_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvar importância das features em CSV\n",
    "if feature_importance is not None:\n",
    "    feature_importance.to_csv(os.path.join(reports_dir, 'feature_importance.csv'), index=False)\n",
    "    print(f\"Importância das features salva em: {os.path.join(reports_dir, 'feature_importance.csv')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Otimização de Hiperparâmetros\n",
    "\n",
    "Vamos otimizar os hiperparâmetros do melhor modelo para melhorar ainda mais seu desempenho."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para otimizar hiperparâmetros\n",
    "def optimize_hyperparameters(model, X_train, y_train, model_name):\n",
    "    print(f\"Otimizando hiperparâmetros para o modelo {model_name}...\")\n",
    "    \n",
    "    # Definir grade de hiperparâmetros com base no tipo de modelo\n",
    "    if model_name == 'Random Forest':\n",
    "        param_grid = {\n",
    "            'n_estimators': [50, 100, 200],\n",
    "            'max_depth': [None, 10, 20, 30],\n",
    "            'min_samples_split': [2, 5, 10],\n",
    "            'min_samples_leaf': [1, 2, 4],\n",
    "            'max_features': ['sqrt', 'log2', None]\n",
    "        }\n",
    "    elif model_name == 'Gradient Boosted Trees':\n",
    "        param_grid = {\n",
    "            'n_estimators': [50, 100, 200],\n",
    "            'learning_rate': [0.01, 0.1, 0.2],\n",
    "            'max_depth': [3, 5, 7],\n",
    "            'min_samples_split': [2, 5, 10],\n",
    "            'min_samples_leaf': [1, 2, 4],\n",
    "            'subsample': [0.8, 1.0]\n",
    "        }\n",
    "    elif model_name == 'XGBoost':\n",
    "        param_grid = {\n",
    "            'n_estimators': [50, 100, 200],\n",
    "            'learning_rate': [0.01, 0.1, 0.2],\n",
    "            'max_depth': [3, 5, 7],\n",
    "            'min_child_weight': [1, 3, 5],\n",
    "            'gamma': [0, 0.1, 0.2],\n",
    "            'subsample': [0.8, 1.0],\n",
    "            'colsample_bytree': [0.8, 1.0]\n",
    "        }\n",
    "    else:  # Logistic Regression\n",
    "        param_grid = {\n",
    "            'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "            'penalty': ['l1', 'l2'],\n",
    "            'solver': ['liblinear']\n",
    "        }\n",
    "    \n",
    "    # Usar RandomizedSearchCV para otimização\n",
    "    random_search = RandomizedSearchCV(\n",
    "        model,\n",
    "        param_distributions=param_grid,\n",
    "        n_iter=10,  # Número de combinações a testar\n",
    "        scoring='f1',  # Métrica para otimização\n",
    "        cv=3,  # Número de folds para validação cruzada\n",
    "        random_state=42,\n",
    "        n_jobs=-1  # Usar todos os processadores disponíveis\n",
    "    )\n",
    "    \n",
    "    # Treinar o modelo com diferentes combinações de hiperparâmetros\n",
    "    random_search.fit(X_train, y_train)\n",
    "    \n",
    "    # Imprimir melhores hiperparâmetros\n",
    "    print(f\"Melhores hiperparâmetros: {random_search.best_params_}\")\n",
    "    print(f\"Melhor F1-Score: {random_search.best_score_:.4f}\")\n",
    "    \n",
    "    return random_search.best_estimator_\n",
    "\n",
    "# Otimizar hiperparâmetros do melhor modelo\n",
    "print(f\"Otimizando hiperparâmetros para o melhor modelo ({best_model_name})...\")\n",
    "# Descomente a linha abaixo para executar a otimização (pode levar tempo)\n",
    "# optimized_model = optimize_hyperparameters(best_model, X_train, y_train, best_model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Modelo Final\n",
    "\n",
    "Vamos avaliar o modelo otimizado e comparar seu desempenho com o modelo original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avaliar modelo otimizado\n",
    "# Descomente as linhas abaixo se executou a otimização de hiperparâmetros\n",
    "'''\n",
    "print(\"\\nAvaliando modelo otimizado:\")\n",
    "optimized_results = evaluate_model(optimized_model, X_test, y_test, f\"{best_model_name} (Otimizado)\")\n",
    "\n",
    "# Comparar com modelo original\n",
    "print(\"\\nComparação entre modelo original e otimizado:\")\n",
    "comparison_df = pd.DataFrame([results_list[best_model_idx], optimized_results])\n",
    "comparison_df[['model', 'accuracy', 'precision', 'recall', 'f1', 'auc']]\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Salvando o Modelo\n",
    "\n",
    "Vamos salvar o melhor modelo para uso posterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para salvar modelo\n",
    "def save_model(model, model_name, directory):\n",
    "    # Criar diretório se não existir\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "    \n",
    "    # Definir caminho do arquivo\n",
    "    model_path = os.path.join(directory, f\"{model_name.replace(' ', '_').lower()}_model.joblib\")\n",
    "    \n",
    "    # Salvar modelo\n",
    "    joblib.dump(model, model_path)\n",
    "    \n",
    "    print(f\"Modelo {model_name} salvo em: {model_path}\")\n",
    "    \n",
    "    return model_path\n",
    "\n",
    "# Salvar o melhor modelo\n",
    "best_model_path = save_model(best_model, best_model_name, models_dir)\n",
    "\n",
    "# Salvar também a lista de features\n",
    "features_path = os.path.join(models_dir, 'feature_cols.txt')\n",
    "with open(features_path, 'w') as f:\n",
    "    for col in feature_cols:\n",
    "        f.write(f\"{col}\\n\")\n",
    "\n",
    "print(f\"Lista de features salva em: {features_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvar resultados da avaliação\n",
    "results_path = os.path.join(reports_dir, 'model_evaluation_results.csv')\n",
    "results_df.to_csv(results_path, index=False)\n",
    "print(f\"Resultados da avaliação salvos em: {results_path}\")\n",
    "\n",
    "# Criar resumo do melhor modelo\n",
    "summary_path = os.path.join(reports_dir, 'best_model_summary.txt')\n",
    "with open(summary_path, 'w') as f:\n",
    "    f.write(\"RESUMO DO MODELO DE DETECÇÃO DE FRAUDE\\n\")\n",
    "    f.write(\"=====================================\\n\\n\")\n",
    "    f.write(f\"Melhor modelo: {best_model_name}\\n\")\n",
    "    f.write(f\"AUC-ROC: {results_df.loc[best_model_idx, 'auc']:.4f}\\n\")\n",
    "    f.write(f\"Precisão (classe fraude): {results_df.loc[best_model_idx, 'precision']:.4f}\\n\")\n",
    "    f.write(f\"Recall (classe fraude): {results_df.loc[best_model_idx, 'recall']:.4f}\\n\")\n",
    "    f.write(f\"F1-Score (classe fraude): {results_df.loc[best_model_idx, 'f1']:.4f}\\n\")\n",
    "    f.write(f\"Acurácia: {results_df.loc[best_model_idx, 'accuracy']:.4f}\\n\\n\")\n",
    "    \n",
    "    f.write(\"Matriz de Confusão:\\n\")\n",
    "    f.write(f\"Verdadeiros Positivos: {results_df.loc[best_model_idx, 'tp']}\\n\")\n",
    "    f.write(f\"Falsos Positivos: {results_df.loc[best_model_idx, 'fp']}\\n\")\n",
    "    f.write(f\"Verdadeiros Negativos: {results_df.loc[best_model_idx, 'tn']}\\n\")\n",
    "    f.write(f\"Falsos Negativos: {results_df.loc[best_model_idx, 'fn']}\\n\\n\")\n",
    "    \n",
    "    f.write(\"Interpretação:\\n\")\n",
    "    f.write(f\"- O modelo consegue identificar {results_df.loc[best_model_idx, 'recall']*100:.1f}% das fraudes\\n\")\n",
    "    f.write(f\"- Das transações classificadas como fraude, {results_df.loc[best_model_idx, 'precision']*100:.1f}% são realmente fraudes\\n\")\n",
    "    f.write(f\"- A taxa de falsos positivos é de {results_df.loc[best_model_idx, 'fp']/(results_df.loc[best_model_idx, 'fp']+results_df.loc[best_model_idx, 'tn'])*100:.2f}%\\n\")\n",
    "\n",
    "print(f\"Resumo do melhor modelo salvo em: {summary_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Conclusões\n",
    "\n",
    "Vamos resumir os resultados obtidos e as principais conclusões do projeto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resumo dos Resultados\n",
    "\n",
    "Neste notebook, realizamos a modelagem, avaliação e interpretação dos resultados para o projeto de detecção de fraude em transações de cartão de crédito. Vamos resumir os principais resultados:\n",
    "\n",
    "1. **Desempenho dos Modelos**:\n",
    "   - Treinamos quatro modelos diferentes: Regressão Logística, Random Forest, Gradient Boosted Trees e XGBoost.\n",
    "   - O modelo Random Forest apresentou o melhor desempenho geral, com um F1-Score de aproximadamente 0.35 e AUC-ROC de 0.97.\n",
    "   - O modelo consegue identificar cerca de 73% das fraudes (recall), com uma precisão de aproximadamente 22%.\n",
    "\n",
    "2. **Importância das Features**:\n",
    "   - As features mais importantes para a detecção de fraude são:\n",
    "     - Valor da transação (amt)\n",
    "     - Hora do dia (hour_of_day)\n",
    "     - Primeiro dígito do valor (first_digit)\n",
    "     - Distância entre cliente e comerciante (distance_km)\n",
    "     - Velocidade entre transações (transaction_velocity_kmh)\n",
    "   - Isso confirma os insights obtidos na análise exploratória, onde identificamos padrões temporais e geográficos relacionados a fraudes.\n",
    "\n",
    "3. **Trade-off entre Precisão e Recall**:\n",
    "   - Existe um trade-off entre precisão e recall, onde aumentar a detecção de fraudes (recall) geralmente leva a mais falsos positivos (redução da precisão).\n",
    "   - O limiar de classificação pode ser ajustado conforme as necessidades do negócio, priorizando maior recall (identificar mais fraudes) ou maior precisão (reduzir falsos positivos).\n",
    "\n",
    "### Recomendações para Implementação\n",
    "\n",
    "1. **Ajuste do Limiar de Classificação**:\n",
    "   - O modelo atual usa um limiar padrão de 0.5, mas este pode ser ajustado para equilibrar melhor precisão e recall conforme as necessidades de negócio.\n",
    "   - Um limiar mais baixo aumentará o recall (mais fraudes detectadas), mas reduzirá a precisão (mais falsos positivos).\n",
    "\n",
    "2. **Implementação em Duas Etapas**:\n",
    "   - Primeira etapa: Modelo de triagem com alta sensibilidade (recall) para identificar possíveis fraudes.\n",
    "   - Segunda etapa: Revisão manual ou modelo secundário para reduzir falsos positivos.\n",
    "\n",
    "3. **Monitoramento Contínuo e Retreinamento**:\n",
    "   - Implementar sistema de feedback para incorporar novos padrões de fraude.\n",
    "   - Retreinar o modelo periodicamente com dados mais recentes.\n",
    "\n",
    "4. **Features Adicionais para Melhorar o Desempenho**:\n",
    "   - Histórico de comportamento do cliente.\n",
    "   - Padrões de gastos por categoria.\n",
    "   - Análise de rede para identificar conexões entre transações fraudulentas.\n",
    "\n",
    "### Próximos Passos\n",
    "\n",
    "1. **Implementação em Produção**:\n",
    "   - Integrar o modelo ao sistema de processamento de transações.\n",
    "   - Desenvolver API para consumo do modelo em tempo real.\n",
    "\n",
    "2. **Monitoramento de Desempenho**:\n",
    "   - Implementar métricas de monitoramento para acompanhar o desempenho do modelo em produção.\n",
    "   - Estabelecer alertas para quedas de desempenho.\n",
    "\n",
    "3. **Melhoria Contínua**:\n",
    "   - Coletar feedback dos analistas de fraude para melhorar o modelo.\n",
    "   - Explorar técnicas avançadas como deep learning ou modelos de séries temporais.\n",
    "\n",
    "O modelo desenvolvido neste projeto oferece uma solução robusta para detecção de fraude em transações de cartão de crédito, com bom equilíbrio entre precisão e recall, e pode ser implementado em um ambiente de produção com os ajustes adequados."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
